# app.py
import streamlit as st
import pandas as pd
import os
import time
from dotenv import load_dotenv # Si on utilise .env en plus

# Importer depuis les modules src
from src.config import (DEFAULT_MODEL_REPO_ID, PROMPT_FILE, IMAGE_DIR,
                        REMOVE_BG_DEFAULT, RESIZE_IMAGE_DEFAULT, DEFAULT_IMAGE_SIZE)
from src.db_handler import get_db_connection, close_db_connection, fetch_all_enhanced_data
from src.llm_models import initialize_llm
from src.graph_workflow import build_graph, WorkflowState
# S'assurer que Pillow/rembg sont bien install√©s
try:
    from src.image_processor import check_rembg_availability
    REM_BG_AVAILABLE = check_rembg_availability()
except ImportError:
     REM_BG_AVAILABLE = False


# --- Configuration de la Page ---
st.set_page_config(layout="wide", page_title="Am√©lioration Produit IA V2")
st.title("üöÄ Am√©lioration Produit V2 (Agents & LangGraph)")

# --- Chargement Configuration & Secrets ---
# load_dotenv() # D√©commenter si .env est utilis√©
hf_api_key = st.secrets.get("HUGGINGFACEHUB_API_TOKEN")
# Cr√©er dossier images si besoin
if not os.path.exists(IMAGE_DIR):
    os.makedirs(IMAGE_DIR)

if not hf_api_key:
    st.error("Veuillez configurer `HUGGINGFACEHUB_API_TOKEN` dans `.streamlit/secrets.toml`")
    st.stop()

# --- Initialisation (Lazy) ---
# Connexion DB (g√©r√©e par Streamlit via cache_resource)
@st.cache_resource
def cached_get_db_connection():
    return get_db_connection()

conn = cached_get_db_connection()

# Graphe LangGraph (compil√© une fois)
@st.cache_resource
def get_compiled_graph():
    return build_graph()

app_graph = get_compiled_graph()

# --- Barre Lat√©rale ---
st.sidebar.header("Configuration")
model_repo_id = st.sidebar.text_input("Mod√®le Hugging Face Repo ID", DEFAULT_MODEL_REPO_ID)

# Initialisation LLM (peut √™tre mise en cache aussi si l'API Key ne change pas)
# @st.cache_resource # Attention si model_repo_id change
def get_llm_client(repo_id, key):
     return initialize_llm(repo_id, key)

llm = get_llm_client(model_repo_id, hf_api_key)

if not llm:
    st.sidebar.error("Impossible d'initialiser le LLM. V√©rifiez l'ID et la cl√© API.")
    st.stop()

st.sidebar.header("Options de Traitement")
# Chargement/√âdition du Prompt
try:
    with open(PROMPT_FILE, 'r', encoding='utf-8') as f:
        default_prompt = f.read()
except Exception as e:
    st.sidebar.error(f"Erreur chargement prompt ({PROMPT_FILE}): {e}")
    default_prompt = "Erreur chargement prompt."

editable_prompt = st.sidebar.text_area(
    "Prompt pour l'am√©lioration:",
    value=default_prompt,
    height=300
)

# Options Image
harmonize_images = st.sidebar.checkbox("‚ú® Harmoniser les images produits", value=True)
image_options = {}
if harmonize_images:
    image_options['remove_bg'] = st.sidebar.checkbox("Enlever le fond", value=REMOVE_BG_DEFAULT, disabled=not REM_BG_AVAILABLE)
    image_options['resize'] = st.sidebar.checkbox("Redimensionner", value=RESIZE_IMAGE_DEFAULT)
    if image_options['resize']:
        img_width = st.sidebar.number_input("Largeur max", min_value=50, max_value=2000, value=DEFAULT_IMAGE_SIZE[0])
        img_height = st.sidebar.number_input("Hauteur max", min_value=50, max_value=2000, value=DEFAULT_IMAGE_SIZE[1])
        image_options['max_size'] = (img_width, img_height)
    if not REM_BG_AVAILABLE and image_options.get('remove_bg'):
         st.sidebar.warning("'rembg' non trouv√©. L'option 'Enlever le fond' est d√©sactiv√©e.")

# --- Section Upload ---
st.header("1. Charger Fichier(s) CSV Produit")
uploaded_files = st.file_uploader(
    "S√©lectionnez ou glissez-d√©posez vos fichiers CSV",
    type=["csv"],
    accept_multiple_files=True
)

# --- Section Lancement Workflow ---
st.header("2. Lancer le Traitement Agentique")
if st.button("üöÄ Lancer l'Am√©lioration", type="primary", disabled=not uploaded_files):
    if not llm:
        st.error("LLM non disponible.")
    elif not editable_prompt or editable_prompt == "Erreur chargement prompt.":
         st.error("Prompt non valide.")
    else:
        # Pr√©parer l'√©tat initial pour le graphe
        initial_state = WorkflowState(
            uploaded_files=uploaded_files,
            raw_dataframe=None,
            mapped_data=[],
            processing_options={
                "prompt": editable_prompt,
                "harmonize_images": harmonize_images,
                "image_options": image_options
            },
            llm_client=llm,
            results=[],
            errors=[],
            # Passer la connexion DB (attention √† la gestion du cycle de vie si non cach√©e)
            db_connection=conn
        )

        st.info("Lancement du workflow agentique... Suivez la progression dans la console/logs.")
        final_state = None
        with st.spinner("Ex√©cution des agents..."):
            try:
                # Invoquer le graphe LangGraph
                # Le graphe ex√©cute les n≈ìuds s√©quentiellement comme d√©fini
                final_state = app_graph.invoke(initial_state)

                st.success("Workflow termin√© !")

                # Afficher les erreurs globales du workflow
                if final_state and final_state.get('errors'):
                    st.warning("Des erreurs sont survenues pendant le traitement :")
                    for error in final_state['errors']:
                        st.error(f"- {error}")

            except Exception as e:
                st.error(f"Erreur critique lors de l'ex√©cution du graphe : {e}")
                # Afficher l'√©tat partiel si disponible
                if final_state:
                     st.write("√âtat partiel:", final_state)


        # --- Affichage des R√©sultats (depuis l'√©tat final) ---
        st.header("3. R√©sultats")
        if final_state and final_state.get('results'):
            df_results = pd.DataFrame(final_state['results'])
            st.dataframe(df_results) # Affichage tabulaire simple

            # Affichage d√©taill√© (optionnel)
            st.subheader("D√©tails par Produit")
            for index, res_row in df_results.iterrows():
                st.markdown(f"--- **Produit ID: {res_row.get('product_id', 'N/A')}** ---")
                col_res1, col_res2 = st.columns(2)
                with col_res1:
                    st.write("**Titre G√©n√©r√©/Original:**")
                    st.text(res_row.get('generated_title', 'N/A'))
                    st.write("**Description Am√©lior√©e:**")
                    st.markdown(res_row.get('enhanced_description', 'N/A').replace('\n', '  \n'))
                    if res_row.get('processing_error'):
                        st.error(f"Erreur sp√©cifique: {res_row['processing_error']}")
                with col_res2:
                    st.write("**Image Originale:**")
                    if pd.notna(res_row.get('image_source')):
                        st.image(res_row['image_source'], width=150)
                    else:
                        st.caption("Pas d'image source")
                    st.write("**Image Trait√©e:**")
                    if pd.notna(res_row.get('processed_image_path')) and isinstance(res_row.get('processed_image_path'), str) and os.path.exists(res_row['processed_image_path']):
                        st.image(res_row['processed_image_path'], width=150)
                    elif res_row.get('processed_image_path'):
                        st.caption(f"Image non affichable ou erreur: {res_row.get('processed_image_path')}")
                    else:
                        st.caption("Pas d'image trait√©e")
                st.divider()


            # --- Export CSV ---
            st.header("4. Exporter les R√©sultats")
            # Re-fetch from DB to ensure consistency or use df_results directly
            csv_export = df_results.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• T√©l√©charger les r√©sultats en CSV",
                data=csv_export,
                file_name=f"enhanced_products_{time.strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
            )
        else:
            st.warning("Aucun r√©sultat √† afficher. V√©rifiez les logs ou les erreurs.")

# --- Affichage Donn√©es Existantes (Optionnel) ---
st.header("Historique des Donn√©es Am√©lior√©es (depuis DuckDB)")
if st.checkbox("Afficher l'historique"):
    try:
        history_df = fetch_all_enhanced_data(conn)
        if not history_df.empty:
            st.dataframe(history_df)
        else:
            st.info("Aucune donn√©e am√©lior√©e n'a encore √©t√© sauvegard√©e.")
    except Exception as e:
        st.error(f"Erreur lors de la r√©cup√©ration de l'historique: {e}")


# Note: La connexion DB est ferm√©e automatiquement par Streamlit √† la fin de la session gr√¢ce √† @st.cache_resource
# Si non cach√©e, il faudrait appeler close_db_connection(conn) quelque part (ex: fin de script, mais complexe avec √©tat Streamlit)

st.sidebar.info("Version 2 - Workflow Agentique")