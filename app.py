# app.py
import streamlit as st
import pandas as pd
import os
import time
from typing import List, Dict, Any, Optional


# --- Configuration et Utilitaires ---
# On importe nos modules maison pour garder le code organis√©
from src.config import (
    DEFAULT_MODEL_REPO_ID,
    PROMPT_FILE,
    IMAGE_DIR,
    REMOVE_BG_DEFAULT,
    RESIZE_IMAGE_DEFAULT,
    DEFAULT_IMAGE_SIZE,
)
from src.db_handler import fetch_all_enhanced_data

from src.llm_models import initialize_llm # pour huggingface (plus de cr√©dit)
from src.llm_models import initialize_google_llm
from src.data_handler import load_and_combine_csvs
from src.utils import is_valid_url, clean_html

# S'assurer que Pillow/rembg sont bien install√©s
try:
    from src.image_processor import check_rembg_availability
    REM_BG_AVAILABLE = check_rembg_availability()
except ImportError:
    REM_BG_AVAILABLE = False

# --- Configuration de la page Streamlit ---
st.set_page_config(layout="wide", page_title="Am√©lioration Produit IA")
st.image("LOGO.png", width=300)
st.title("üöÄ Am√©liorateur de descriptions produits")

# --- Gestion de l'√âtat de Session ---
# Streamlit r√©ex√©cute le script √† chaque interaction.
# st.session_state permet de conserver des informations (donn√©es charg√©es, s√©lections)
# entre ces r√©ex√©cutions, essentiel pour une application interactive.
if "uploaded_files_list" not in st.session_state:
    st.session_state.uploaded_files_list = [] 
if "combined_df" not in st.session_state:
    st.session_state.combined_df = None
if "edited_df" not in st.session_state:
    st.session_state.edited_df = None
if "processing_results" not in st.session_state:
    st.session_state.processing_results = None
if "loading_errors" not in st.session_state:
    st.session_state.loading_errors = []

# --- Chargement configuration & secrets ---
hf_api_key = st.secrets.get("HUGGINGFACEHUB_API_TOKEN")
google_api_key = st.secrets.get("GOOGLE_API_KEY") # Priorit√© √† Google
if not os.path.exists(IMAGE_DIR):
    os.makedirs(IMAGE_DIR)

# --- V√©rification des cl√©s API ---
if not hf_api_key:
    st.error(
        "Veuillez configurer `HUGGINGFACEHUB_API_TOKEN` dans `.streamlit/secrets.toml`"
    )
    st.stop()
if not google_api_key: 
    st.error("Veuillez configurer `GOOGLE_API_KEY` dans `.streamlit/secrets.toml`")
    st.stop()


# --- Initialisation des Ressources Mises en Cache ---
# Utiliser @st.cache_resource pour les objets lourds ou non s√©rialisables
# comme les connexions DB, les graphes LangChain, ou les clients LLM.
# Cela √©vite de les recr√©er √† chaque interaction.
@st.cache_resource
def cached_get_db_connection():
    from src.db_handler import get_db_connection
    return get_db_connection()

@st.cache_resource
def get_compiled_graph():
    from src.graph_workflow import build_graph
    return build_graph()

@st.cache_resource 
def get_llm_client_cached(model_name, key):
    print(f"Tentative d'initialisation LLM Google pour {model_name}")
    return initialize_google_llm(model_name=model_name, api_key=key)

# Obtenir les ressources initialis√©es (r√©cup√©r√©es du cache si d√©j√† cr√©√©es)
conn = cached_get_db_connection()
app_graph = get_compiled_graph()

# --- Barre Lat√©rale de configuration ---
with st.sidebar:
    st.header("‚öôÔ∏è Configuration g√©n√©rale")
    # model_repo_id = st.text_input("Mod√®le Hugging Face Repo ID", DEFAULT_MODEL_REPO_ID)
    google_model_name = st.selectbox(
        "Mod√®le Google AI",
        ["models/gemma-3-27b-it", "models/gemma-3-12b-it", "gemini-1.5-flash", "gemini-1.0-pro", "models/gemini-1.5-pro-latest"],
        index=0,
        help="Choisissez le mod√®le d'IA pour la g√©n√©ration."
    )

    # Initialisation LLM (cache bas√© sur le nom du mod√®le et la cl√©)
    llm = get_llm_client_cached(google_model_name, google_api_key)

    if not llm:
        st.error("Impossible d'initialiser le LLM Google.")


    # --- Prompt d'am√©lioration ---
    st.header("üìù Prompt d'am√©lioration")
    try:
        with open(PROMPT_FILE, "r", encoding="utf-8") as f:
            default_prompt = f.read()
    except Exception as e:
        st.error(f"Erreur chargement prompt ({PROMPT_FILE}): {e}")
        default_prompt = "Erreur chargement prompt."

    editable_prompt = st.text_area(
        "Adaptez le prompt si besoin:", value=default_prompt, height=250
    )

    # --- Options de traitement des images ---
    st.header("üñºÔ∏è Options image")
    harmonize_images = st.checkbox("Harmoniser les images", value=True)
    image_options = {}
    if harmonize_images:
        image_options["remove_bg"] = st.checkbox(
            "Enlever le fond", value=REMOVE_BG_DEFAULT, disabled=not REM_BG_AVAILABLE
        )
        image_options["resize"] = st.checkbox(
            "Redimensionner", value=RESIZE_IMAGE_DEFAULT
        )
        if image_options["resize"]:
            img_width = st.number_input(
                "Largeur max", min_value=50, max_value=2000, value=DEFAULT_IMAGE_SIZE[0]
            )
            img_height = st.number_input(
                "Hauteur max", min_value=50, max_value=2000, value=DEFAULT_IMAGE_SIZE[1]
            )
            image_options["max_size"] = (img_width, img_height)
        image_options['force_format'] = st.selectbox("Forcer Format Sortie", [None, "PNG", "JPEG", "WEBP"], index=0)
        image_options['overwrite'] = st.checkbox("√âcraser images existantes", value=False)
        if REM_BG_AVAILABLE:
            image_options['rembg_model'] = st.selectbox("Mod√®le Rembg", ["u2net", "u2netp", "silueta"], index=0) # Exemple
        if image_options['force_format'] == 'JPEG':
            image_options['jpeg_quality'] = st.slider("Qualit√© JPEG", 50, 100, 90)
        if not REM_BG_AVAILABLE and image_options.get("remove_bg"):
            st.warning("'rembg' non trouv√©.", icon="‚ö†Ô∏è")


# --- Section principale du streamlit---

# √âtape 1 : Upload des fichiers
st.header("1. Charger les descriptions")
uploaded_files = st.file_uploader(
    "S√©lectionnez ou glissez-d√©posez vos fichiers CSV",
    type=["csv"],
    accept_multiple_files=True,
    key="file_uploader",  # cl√© pour potentiellement r√©initialiser
)

# logique pour recharger les donn√©es si les fichiers upload√©s changent
if uploaded_files != st.session_state.uploaded_files_list:
    st.session_state.uploaded_files_list = uploaded_files
    st.session_state.combined_df = None
    st.session_state.edited_df = None
    st.session_state.processing_results = None
    st.session_state.loading_errors = []
    if uploaded_files:
        st.info(
            f"{len(uploaded_files)} fichier(s) s√©lectionn√©(s). Chargement et combinaison..."
        )
        # Charger et combiner imm√©diatement
        combined_df, errors = load_and_combine_csvs(uploaded_files)
        st.session_state.combined_df = combined_df
        st.session_state.loading_errors = errors
        if combined_df is not None:
            # pr√©parer pour l'√©diteur
            if "Select" not in combined_df.columns:
                combined_df.insert(0, "Select", False)
            st.session_state.edited_df = (
                combined_df.copy()
            )  # init l'√©diteur avec le DF charg√©
        st.rerun()  # forcer un re-run pour afficher le data_editor

# Afficher les erreurs de chargement s'il y en a
if st.session_state.loading_errors:
    st.warning("Erreurs lors du chargement des fichiers CSV :")
    for error in st.session_state.loading_errors:
        st.error(f"- {error}")

# √âtape 2: pr√©visualisation et s√©lection
st.header("2. Pr√©visualiser et s√©lectionner les produits")

if st.session_state.edited_df is not None and not st.session_state.edited_df.empty:
    st.info("Cochez les lignes que vous souhaitez traiter.")

    # boutons de s√©lection/d√©s√©lection rapide
    col_btn1, col_btn2, _ = st.columns([1, 1, 4])
    with col_btn1:
        if st.button("Tout S√©lectionner", key="select_all"):
            st.session_state.edited_df["Select"] = True
            st.rerun()
    with col_btn2:
        if st.button("Tout D√©s√©lectionner", key="deselect_all"):
            st.session_state.edited_df["Select"] = False
            st.rerun()

    # configuration des colonnes pour l'√©diteur (rend les colonnes sources non modifiables)
    column_config = {
        "Select": st.column_config.CheckboxColumn(required=True, default=False),
    }
    potential_image_cols = [
        "image_source",
        "image_url",
        "image",
        "Image Source",
        "Image URL",
    ]
    image_col_found = None
    for col in potential_image_cols:
        if col in st.session_state.edited_df.columns:
            image_col_found = col
            break

    # ajouter la config pour l'image si trouv√©e
    if image_col_found:
        column_config[image_col_found] = st.column_config.ImageColumn(
            label="üñºÔ∏è Aper√ßu Image",
            help="Aper√ßu de l'image depuis l'URL source",
            width="small",  # ou "medium"
        )
    # d√©sactiver l'√©dition des autres colonnes sources
    for col in st.session_state.edited_df.columns:
        if (
            col != "Select" and col not in column_config
        ):
            column_config[col] = st.column_config.Column(disabled=True)

    # afficher le data editor
    edited_df_result = st.data_editor(
        st.session_state.edited_df,
        key="data_editor",  # cl√© pour acc√©der √† l'√©tat √©dit√©
        use_container_width=True,
        hide_index=True,
        column_config=column_config,
        num_rows="dynamic",  # garder dynamique pour voir toutes les lignes
    )

    # Mettre √† jour l'√©tat de session avec les modifications pas l'utilisateur
    # V√©rifier si l'objet retourn√© est diff√©rent (signifie une √©dition)
    # Note: C'est un peu d√©licat, parfois il vaut mieux juste relire la cl√©
    st.session_state.edited_df = (
        edited_df_result  # L'√©tat est mis √† jour par st.data_editor lui-m√™me via sa cl√©
    )

    # affiche les lignes s√©lectionn√©es
    selected_rows_df = st.session_state.edited_df[st.session_state.edited_df["Select"]]
    st.info(f"**{len(selected_rows_df)}** produit(s) s√©lectionn√©(s) pour traitement.")

else:
    st.warning("Veuillez charger un ou plusieurs fichiers CSV pour commencer.")


# √âtape 3: Lancer le traitement agentique de la description
st.header("3. Lancer le traitement IA")

button_disabled = (
    llm is None
    or not editable_prompt
    or editable_prompt == "Erreur chargement prompt."
    or st.session_state.edited_df is None
    or st.session_state.edited_df[st.session_state.edited_df["Select"]].empty
)

if st.button(
    "‚ú® Lancer l'am√©lioration sur la s√©lection",
    type="primary",
    disabled=button_disabled,
):
    selected_df_to_process = st.session_state.edited_df[
        st.session_state.edited_df["Select"]
    ].copy()

    # pr√©parer l'√©tat initial pour LangGraph
    initial_state = {
        "selected_dataframe": selected_df_to_process,
        "mapped_data": [],
        "processing_options": {
            "prompt": editable_prompt,
            "harmonize_images": harmonize_images,
            "image_options": image_options,
        },
        "llm_client": llm,
        "results": [],
        "errors": [],
        # "db_connection": conn,
    }

    st.info("Lancement du workflow agentique...")
    final_state = None
    node_statuses = {}  # Pour suivre l'√©tat de chaque noeud

    # utiliser st.status pour afficher la progression dynamique
    with st.status(
        "üöÄ Initialisation du workflow...", expanded=True
    ) as status_container:
        try:
            # ex√©cute le graphe en mode streaming pour suivre les √©tapes
            event_stream = app_graph.stream(initial_state, stream_mode="values")

            for event in event_stream:
                # la structure de l'√©v√©nement est un dictionnaire o√π les cl√©s sont les noms des noeuds
                # et les valeurs sont les sorties de ces noeuds (l'√©tat mis √† jour)
                # on peut d√©tecter quel noeud vient de s'ex√©cuter
                final_state = event # garder l'√©tat complet le plus r√©cent
                latest_node = list(event.keys())[
                    -1
                ]

                if latest_node not in node_statuses:
                    node_statuses[latest_node] = "running"
                    st.write(f"‚ñ∂Ô∏è √âtape: **{latest_node}**")
                    status_container.update(label=f"‚è≥ En cours: {latest_node}...")

                # afficher des d√©tails de l'√©tat pour debug
                st.write(f"√âtat apr√®s {latest_node}: {final_state}")
            # une fois la boucle termin√©e, le workflow est fini
            # V√©rifier l'√©tat final apr√®s la fin du stream
            if isinstance(final_state, dict):
                status_container.update(label="‚úÖ Workflow termin√© !", state="complete", expanded=False)
                st.session_state.processing_results = final_state
                st.success("Traitement termin√© !")
                if final_state.get('errors'):
                    st.warning("Des erreurs globales sont survenues :")
                    for error in final_state['errors']: st.error(f"- {error}")
            else:
                error_msg = f"Erreur interne: √âtat final invalide (type: {type(final_state)})."
                print(error_msg) # Log pour debug
                st.error(error_msg)
                status_container.update(label="‚ùå Erreur Workflow", state="error", expanded=True)
                st.session_state.processing_results = None

        except Exception as e:
            st.error(f"Erreur critique lors de l'ex√©cution du graphe : {e}")
            st.exception(e) # Affiche la trace compl√®te pour le debug
            status_container.update(label="‚ùå Erreur Critique Workflow", state="error", expanded=True)
            st.session_state.processing_results = final_state if isinstance(final_state, dict) else {"errors": [f"Erreur critique: {e}", f"√âtat final partiel: {final_state}"]}

# √âtape 4. affichage des r√©sultats
st.header("4. R√©sultats du traitement")

if isinstance(st.session_state.processing_results, dict) and st.session_state.processing_results.get('results'):
    results_list = st.session_state.processing_results["results"]
    df_results = pd.DataFrame(results_list)

    st.success(f"{len(df_results)} produits trait√©s avec succ√®s (voir d√©tails ci-dessous).")
    # st.dataframe(df_results)

    # affichage d√©taill√© dans des expanders pour garder l'interface propre
    st.subheader("D√©tails par produit trait√©")
    for index, res_row in df_results.iterrows():
        # Utiliser l'ID produit comme titre de section si disponible
        product_id_display = res_row.get("product_id", f"Ligne {index+1}")
        with st.expander(f"**Produit ID: {product_id_display}**", expanded=False):
            col_res1, col_res2 = st.columns(2)
            with col_res1:
                st.write("**Titre g√©n√©r√©/original:**")
                st.caption(res_row.get("generated_title", "N/A"))
                st.write(
                    "**Description originale (nettoy√©e):**"
                )
                cleaned_original = clean_html(res_row.get("original_body_html", ""))
                st.text_area("", value=cleaned_original, height=150, disabled=True, key=f"clean_orig_{product_id_display}")
                st.write("**Image originale:**")
                img_src = res_row.get("image_source")
                if img_src and pd.notna(img_src) and is_valid_url(img_src):
                    st.image(img_src, width=150)
                else:
                    st.caption("Pas d'image source valide")

            with col_res2:
                st.write("**Description am√©lior√©e:**")
                st.markdown(
                    res_row.get(
                        "enhanced_description", "*Aucune description g√©n√©r√©e*"
                    ).replace("\n", "  \n")
                )
                st.write("**Image trait√©e:**")
                img_processed = res_row.get("processed_image_path")
                if (
                    img_processed
                    and pd.notna(img_processed)
                    and isinstance(img_processed, str)
                    and os.path.exists(img_processed)
                ):
                    st.image(img_processed, width=150)
                elif img_processed:
                    st.caption(f"Image non affichable ({img_processed})")
                else:
                    st.caption("Pas d'image trait√©e")

                # Afficher l'erreur sp√©cifique au produit si elle existe
                if pd.notna(res_row.get("processing_error")):
                    st.error(
                        f"Erreur sp√©cifique: {res_row['processing_error']}", icon="üö®"
                    )

    # Etape 5: export CSV
    st.header("5. Exporter les r√©sultats")
    csv_export = df_results.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="üì• T√©l√©charger les r√©sultats trait√©s en CSV",
        data=csv_export,
        file_name=f"enhanced_products_{time.strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
    )
    # g√©rer le cas o√π le traitement a eu lieu mais sans r√©sultats (ex: erreur globale)
elif st.session_state.processing_results:
    st.warning("Le traitement s'est termin√© mais aucun r√©sultat structur√© n'a √©t√© trouv√© dans l'√©tat final.")
    # afficher les erreurs globales si elles existent, m√™me si results est vide/manquant
    if isinstance(st.session_state.processing_results, dict) and st.session_state.processing_results.get('errors'):
        st.warning("Erreurs globales report√©es :")
        for error in st.session_state.processing_results['errors']:
            st.error(f"- {error}")


# Etape 6: historique
st.header("üìö Historique complet (depuis DuckDB)")
if st.checkbox("Afficher l'historique complet"):
    try:
        history_df = fetch_all_enhanced_data(conn)
        if not history_df.empty:
            st.dataframe(history_df, use_container_width=True)
        else:
            st.info("Aucune donn√©e am√©lior√©e n'a encore √©t√© sauvegard√©e dans la base.")
    except Exception as e:
        st.error(f"Erreur lors de la r√©cup√©ration de l'historique: {e}")

st.sidebar.info("Application d'am√©lioration produit TheBradery - Louis Rigaux")
